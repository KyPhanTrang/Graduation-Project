# import os
# import numpy as np
# import pickle
# from tensorflow.keras.models import load_model
# from tensorflow.keras.preprocessing.sequence import pad_sequences
# from tensorflow.keras.utils import to_categorical

# # ==== Tham sá»‘ ====
# DATA_PATH = "C:/Users/admin/Downloads/DATN/Graduation_project/data/"
# TRUNCATE_LENGTH = 300
# TOKENIZER_PATH = "C:/Users/admin/Downloads/DATN/Graduation_project/tokenizer.pkl"
# MODEL_PATH = "C:/Users/admin/Downloads/DATN/Graduation_project/sentiment_model.h5"

# # ==== HÃ m load dá»¯ liá»‡u ====
# def load_data(path, label):
#     texts = []
#     labels = []
#     for fname in os.listdir(path):
#         with open(os.path.join(path, fname), encoding='utf-8') as f:
#             texts.append(f.read())
#             labels.append(label)
#     return texts, labels

# # ==== Load dá»¯ liá»‡u test ====
# pos_test, y_pos_test = load_data(os.path.join(DATA_PATH, "data_test/test/pos"), 1)
# neg_test, y_neg_test = load_data(os.path.join(DATA_PATH, "data_test/test/neg"), 0)
# test_texts = pos_test + neg_test
# test_labels = y_pos_test + y_neg_test

# # ==== Load tokenizer ====
# with open(TOKENIZER_PATH, "rb") as f:
#     tokenizer = pickle.load(f)

# # ==== Tiá»n xá»­ lÃ½ vÄƒn báº£n ====
# test_sequences = tokenizer.texts_to_sequences(test_texts)
# test_data = pad_sequences(test_sequences, maxlen=TRUNCATE_LENGTH)
# test_labels = to_categorical(test_labels)

# # ==== Load mÃ´ hÃ¬nh ====
# model = load_model(MODEL_PATH)

# # ==== ÄÃ¡nh giÃ¡ ====
# loss, accuracy = model.evaluate(test_data, test_labels)
# print(f"\nğŸ¯ Accuracy trÃªn táº­p test: {accuracy:.4f}")

# # ==== Dá»± Ä‘oÃ¡n máº«u ====
# pred_probs = model.predict(test_data)
# pred_labels = np.argmax(pred_probs, axis=1)
# true_labels = np.argmax(test_labels, axis=1)

# print("\nğŸ“ Má»™t vÃ i káº¿t quáº£ dá»± Ä‘oÃ¡n:")
# for i in range(5):
#     print(f"\nVÄƒn báº£n: {test_texts[i][:100]}...")
#     print(f"  âœ… Tháº­t: {true_labels[i]}  |  ğŸ”® Dá»± Ä‘oÃ¡n: {pred_labels[i]}")


import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
import pickle

# ==== Tham sá»‘ ====
MODEL_PATH = "C:/Users/admin/Downloads/DATN/Graduation_project/sentiment_model.h5"
TOKENIZER_PATH = "C:/Users/admin/Downloads/DATN/Graduation_project/tokenizer.pkl"
TRUNCATE_LENGTH = 300  # pháº£i giá»‘ng khi train

# ==== Load model & tokenizer ====
model = load_model(MODEL_PATH)

with open(TOKENIZER_PATH, "rb") as f:
    tokenizer = pickle.load(f)

# ==== VÄƒn báº£n cáº§n dá»± Ä‘oÃ¡n ====
text = "ChÃºng_mÃ¬nh Ä‘i 2 ngÆ°á»i Äƒn láº©u , tÃ¢m_tráº¡ng vui phÆ¡i_phá»›i !Äáº¿n thÃ¬ gáº·p con nhÃ¢n_viÃªn máº·t nhÆ° cÃ³ chuyá»‡n gÃ¬ tá»©c_tá»‘i muá»‘n Ä‘uá»•i khÃ¡ch láº¯m áº¥y , rÃ¡ng nhá»‹n , kÃªu cÃ¡i láº©u vÃ  vÃ i que xiÃªn que Äá»£i mÃ£i khÃ´ng tháº¥y xiÃªn que qua há»i thÃ¬_ra chÆ°a lÃ m = > lÃ½_do : quÃªnKiu nhÃ¢n_viÃªn cho thÃªm nÆ°á»›c_Ä‘Ã¡ , liáº¿c 1 cÃ¡i - _ -Ai_Ä‘á»i Äƒn láº©u tÃ­nh tiá»n mÃ¬ gÃ³i riÃªng , tiá»n rau riÃªng , cÃ¡i bill cáº£ tÃ¡ tiá»n láº·t_váº·tLáº©u thá»‹t cháº£ Ä‘Æ°á»£c bao_nhiÃªu , biáº¿t váº­y Äƒn bÃªn quáº­n 8 tá»‘t hÆ¡n"

# ==== Tiá»n xá»­ lÃ½ ====
sequence = tokenizer.texts_to_sequences([text])
padded = pad_sequences(sequence, maxlen=TRUNCATE_LENGTH)

# ==== Dá»± Ä‘oÃ¡n ====
prediction = model.predict(padded)
label = np.argmax(prediction)

# ==== In káº¿t quáº£ ====
print(f"XÃ¡c suáº¥t dá»± Ä‘oÃ¡n: {prediction}")
print("Káº¿t luáº­n: ", "TÃ­ch cá»±c" if label == 1 else "TiÃªu cá»±c")
